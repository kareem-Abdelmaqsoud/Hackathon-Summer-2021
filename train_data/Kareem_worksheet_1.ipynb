{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_csv('train_expression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      55\n",
       "1      62\n",
       "2      52\n",
       "3      42\n",
       "4      63\n",
       "       ..\n",
       "960    64\n",
       "961    54\n",
       "962    54\n",
       "963    24\n",
       "964    44\n",
       "Name: age, Length: 965, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.read_csv('train_feature_names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_id</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000000003.14</td>\n",
       "      <td>TSPAN6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000000005.5</td>\n",
       "      <td>TNMD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000000419.12</td>\n",
       "      <td>DPM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000000457.13</td>\n",
       "      <td>SCYL3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000000460.16</td>\n",
       "      <td>C1orf112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52930</th>\n",
       "      <td>ENSG00000283695.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52931</th>\n",
       "      <td>ENSG00000283696.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52932</th>\n",
       "      <td>ENSG00000283697.1</td>\n",
       "      <td>HSFX3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52933</th>\n",
       "      <td>ENSG00000283698.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52934</th>\n",
       "      <td>ENSG00000283699.1</td>\n",
       "      <td>MIR4481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52935 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  gene_id    symbol\n",
       "0      ENSG00000000003.14    TSPAN6\n",
       "1       ENSG00000000005.5      TNMD\n",
       "2      ENSG00000000419.12      DPM1\n",
       "3      ENSG00000000457.13     SCYL3\n",
       "4      ENSG00000000460.16  C1orf112\n",
       "...                   ...       ...\n",
       "52930   ENSG00000283695.1       NaN\n",
       "52931   ENSG00000283696.1       NaN\n",
       "52932   ENSG00000283697.1     HSFX3\n",
       "52933   ENSG00000283698.1       NaN\n",
       "52934   ENSG00000283699.1   MIR4481\n",
       "\n",
       "[52935 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_2\n",
    "labels = df['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b7149ad92b0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_2['ENSG00000000005.5'], df['age'], 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAFlCAYAAADYnoD9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAr/UlEQVR4nO3dd3xc1Z338c9P1ZYsWVZxlWS5yBUbF2FjemKKgQ2QbggJELLOJoElWVJI2YTl2eymPEk2eZZNQlhIIwECbOIkphNaACPZuFe5SrKsYnXJajPn+WPGXtmR7bE90tXc+b5fL708t6D5zeF6vr7nnnuuOecQERER7yR4XYCIiEi8UxiLiIh4TGEsIiLiMYWxiIiIxxTGIiIiHlMYi4iIeCzJqzfOzc11RUVFXr29iIjIoFqzZk29cy6vv22ehXFRURFlZWVevb2IiMigMrN9J9qmbmoRERGPKYxFREQ8pjAWERHxmMJYRETEYwpjERERjymMRUREPKYwFhER8ZjCWERExGMKYxEREY8pjEVERDymMBYREfFYRGFsZsvMbLuZlZvZPf1sLzSzv5jZO2a2wcyuiX6pIiIiA6+zJ8CWAy28vL120N7zlA+KMLNE4H7gCqASKDWzlc65LX12+xrwuHPux2Y2C1gFFA1AvSIiIlHR2RNgV10bO2va2Fnbyo6aNnbWtLK/oYOggxGpSWy890rMbMBrieSpTYuAcufcbgAzexS4Hugbxg7IDL8eCRyIZpEiIiJnKhh07G/oYNvBVrYfbGV7TQvbD7ay91AHgaADICnBKMpNZ+a4TK6bN4Hi0SOYNiZj0GqMJIwnABV9liuBxcftcy/wnJndCaQDl/f3i8xsBbACoLCw8HRrFREROam61i62H2xl28EWdtSEwndHTRuHewJH9ynMTmP62AyumTOOaWMymD42g6KcdFKSvBtGFa3nGd8I/Nw59z0zWwL8yszOcc4F++7knHsAeACgpKTERem9RUQkzrR39bKzto3tB1v+94z3YCuH2ruP7pOTnsL0sRksX1TAjLEZTB+bSfHoEaSnRiv6oieSiqqAgj7L+eF1fd0OLANwzr1pZsOAXGDwrn6LiIjvOOeobu5ky4EWtlS3sOVAC1sPtrC/oQMXPqUbnpzItDEjWDpzNNPHZjJjbAbTxmSQl5HqbfGnIZIwLgWKzWwSoRBeDtx03D77gaXAz81sJjAMqItmoSIi4m89gSDltW1Hg3drdejPpo6eo/tMyk1n9vhM3r8gn2ljMpgxNoPC7DQSEgZ+kNVAOmUYO+d6zewO4FkgEXjIObfZzO4DypxzK4G7gZ+Z2ecIDea61TmnbmgREelXS2cPW/uc7W6pbmFnTRvdgdDVzdSkBGaMy+Tqc8Yya1wms8ZnMn1sJiOGYBdzNJhXmVlSUuLKyso8eW8RERkczjkOtnSyqepI6DazpbqFiobDR/fJSU9h1vhQ4M4al8ns8ZkU5aSTlOiveanMbI1zrqS/bf78J4aIiAy6I8G7sbKZjVWhn01VzdS3hQZVmYW6mefmZ7H8vEJmjc9k9rhM8jJSB+Ve3qFMYSwiIqftVMGbYFA8OoPLpo9mzoSRnDNhJDPHZZCWotjpj1pFREROqm/wbqpqZkMEwTtrXCbDUxI9rjx2KIxFROQY9W1drK9oYn1F09GzXgXvwFIYi4jEscPdATYdaGbd/ibWVTaxbn8TVU2hwVVHgvfSaaOZm6/gHUgKYxGROBEIOspr21hX0ci6imbWVzSxvab16PzME7KGM68wi1svKOLcgizOmZCpa7yDRK0sIuJT1c2HWV/RxDtHupwrm2nvDs3RnDEsiXkFWXx65hTOzc/i3IKsmJqxym8UxiIiPtDZE2BTVTNr9jWydn8j6yqaqGnpAiA50Zg1LpMPLMzn3IIs5hVkUZSTHvOzVvmJwlhEJAYdbO5k7f5G1uwL/Ww+0ExPINTdPDEnjSWTc5hXEDrjnTU+k9QkXecdyhTGIiJDXE8gyNbqFtbua2TN/ibW7ms8OsgqNSmBc/OzuP2iySwozGLBxFHkjlB3c6xRGIuIDDEN7d3h4G1k7b5G1lc20dkTmrN53MhhLJg4itsvmsSCiaOYNS7T0+fwSnQojEVEPOScY9+hDt7e20DpngbW7Gtkd307AEkJxuzxmdy4qJCFE0exoHAU47OGe1yxDASFsYjIIAoGHdtrWind28DqPaEArm0NDbQalZbMwonZfLCkgIUTRzE3fyTDknWtNx4ojEVEBlB3b5BNB5p5Oxy8pXsbaOnsBUJdzkum5HBeUTaLJ2UzJW+ERjjHKYWxiEgUdXT38s7+plD47m1g7f7Go9d7J+elc82ccZxXlM2iSdnkjxoe908rkhCFsYjIWWjr6qV0TwNv7T7E6j0NbKpqpjfoMINZ4zJZfl4hiydlU1KUrUk15IQUxiIip6Gju5eyvY28ufsQb+46xMaqZgJBR0piAnPzR7LiksmcNymbhRNHkTks2etyJUYojEVETqKzJ8Da/Y28tesQb+w6xPrKJnoCjqQE49yCLD516RSWTMlhQeEoPUBBzpjCWESkj+7eIOsqmnhz1yHe3F3P2v1NdPcGSTCYM2EkH79oEksmhwZdpafqK1SiQ0eSiMS1QNCxobKJN3aFup3L9jXQ2RM8es33Y+dPDI14npStbmcZMApjEYkrzjn2Hurg9fJ6Xt9Zx5u7Dh291Wj6mAyWn1fI+ZNzOH9yNllpKR5XK/FCYSwivtfQ3s1fy+t5fWc9r5fXH53XeULWcK4+ZxwXFudywZQczeksnlEYi4jvdPYEKN3bED77rWfzgRYg9AzfJZNz+IdLJ3Ph1Fwm5abrPl8ZEhTGIhLzgkHH5gMtofAtr6N0byPdvUGSE435haO4+4ppXFicy9wJI0lK1EMVZOhRGItITKpr7eK1nXW8sqOO13bW09DeDYSu+968eCIXF+eyaJJGPEts0FEqIjGhNxBk7f4mXtlRyys76thUFep6zklP4dJpeVxcnMtFU3MZnTnM40pFTp/CWESGrANNh3l1R+js9/Xyelo7e0lMMBYUZvH5K6dx6bTRzB6fqYcrSMxTGIvIkNHVG6B0T+PRs98dNW1A6OlG184Zx6XT8rhgai4jh+t+X/EXhbGIeOpgcycvbavlpW01/LX8EId7AqQkJrBoUjYfXFjApdPzKB49QqOexdcUxiIyqIJBx4aqZl7aWsOL22qP3naUP2o4HyzJ57LpeZw/OYe0FH09SfzQ0S4iA66tq5fXd9bz4tYa/rK9jvq2LhIMSiZmc8/VM1g6YzRTdfYrcUxhLCIDoqKhgxfDZ7+rdzfQHQiSMSyJy6aPZumM0Vw6LY9R6ZpuUgQUxiISJYGg4539jbywtZYXt9awszY0+GpKXjq3XljEu2eMZuHEUSRr0g2Rv6EwFpEz1tkT4M1dh3huy0Ge31JDfVs3SQnG4snZLF9UyNIZoynKTfe6TJEhT2EsIqelpbOHv2yr5bktNby8rZb27gAjUpO4bHoeV84ey2XT8/SoQZHTFFEYm9ky4IdAIvCgc+5bx23/AfCu8GIaMNo5lxXFOkXEQzUtnTy/pYbnttTw5q56egKO3BGpXDdvAlfNHsOSKTmkJiV6XaZIzDplGJtZInA/cAVQCZSa2Urn3JYj+zjnPtdn/zuB+QNQq4gMol11bTy3uYZnNx9kXUUTAEU5aXz8wklcOXss8wuyNPOVSJREcma8CCh3zu0GMLNHgeuBLSfY/0bgG9EpT0QGi3OOLdUtrNpYzTObDrKrrh2Aufkj+cJV07ly1hjdfiQyQCIJ4wlARZ/lSmBxfzua2URgEvDSCbavAFYAFBYWnlahIhJ9zjk2VbXw543VPL2pmn2HOkhMMM6fnM0tFxRx+cwxjM8a7nWZIr4X7QFcy4EnnHOB/jY65x4AHgAoKSlxUX5vEYmAc471lc08vbGaVZuqqWg4TGKCccGUHD516RSunD2WbN3/KzKoIgnjKqCgz3J+eF1/lgOfOduiRCS6gkHHusomVm2o5ulNB6lqOkxSgnFRcS53vquYK2aN0QQcIh6KJIxLgWIzm0QohJcDNx2/k5nNAEYBb0a1QhE5I8GgY+3+RlZtPMjTm6qpbu4kOdG4uDiPz10xjStmjmFkmm5BEhkKThnGzrleM7sDeJbQrU0POec2m9l9QJlzbmV41+XAo845dT+LeMQ5x7qKJlauP8CqjdXUtHSRkpjAJdPy+MJV01k6c4wePygyBEV0zdg5twpYddy6rx+3fG/0yhKR07GjppU/rKvij+ur2d/QQUpiApdOz+PaOeNYOnM0GZqEQ2RI0wxcIjGqoqGDlesP8Mf1B9h2sJUEgwun5nLHu6dy1eyxOgMWiSEKY5EYUtvayZ83VLNy/QHe2d8EwILCLO59zyyunTuevIxUbwsUkTOiMBYZ4poP9/DspoOsXH+AN3bVE3QwY2wGX1w2nffMHU9BdprXJYrIWVIYiwxBPYEgL2+v43/eqeSFLbV0B4JMzEnjM++aynXnjqd4TIbXJYpIFCmMRYYI5xwbq5p5am0VK9cfoKG9m5z0FG5aXMgN8ydwbv5ITUUp4lMKYxGPHWg6zO/XVfHU2irKa9tISUrgipljeN+CCVwyLY/kxASvSxSRAaYwFvFAe1cvz2w6yFPvVPLGrkM4B+cVjeLf3juHa+eM02QcInFGYSwySIJBx1u7D/HEmkqe3nSQwz0BCrPTuGtpMe+dP4GJOelelygiHlEYiwyw6ubDPFFWyeNrKqhoOEzGsCRumD+B9y+YwMKJo3QdWEQUxiIDobs3yItba3isrIJXd9QRdLBkcg53XzGdZeeMZVhyotclisgQojAWiaIdNa08XlrB/7xTxaH2bsZmDuPTl03lgyX56oYWkRNSGIucpbauXv64/gCPlVawrqKJ5ETj8plj+NB5BVxSnEdigrqhReTkFMYiZ2hDZROPvLWflesPcLgnQPHoEXzt2pm8d/4EckZoWkoRiZzCWOQ0dHT3snLdAR5ZvZ+NVc0MT07kunPH8+FFBcwvyNJgLBE5IwpjkQhsP9jKb1bv46m1VbR29TJ9TAb3XT+bG+ZPIFOPJxSRs6QwFjmBrt4Az2w6yK/f2kfp3kZSEhO4Zs5Ybj5/om5JEpGoUhiLHGffoXZ+s3o/v1tTSUN7NxNz0vjKNTP4wMICstNTvC5PRHxIYSxCaHasl3fU8vM39vHqjjoSE4wrZo7h5vMncsGUHBI0IlpEBpDCWOJaS2cPT5RV8ss397L3UAdjMlP53OXTWL6ogDGZw7wuT0TihMJY4lJ5bRu/fHMvT66ppL07wMKJo7j7ytDsWHpKkogMNoWxxI0jXdEP/3Uvr+2sJyUxgfecO55bLyhiTv5Ir8sTkTimMBbfa+ns4Xfhruh94a7ou6+Yxo2LC8nV5BwiMgQojMW3Khs7ePive3mstIK2rl4WThzF59UVLSJDkMJYfGdDZRM/e20PqzZWA/B3c8dx+0WTmJuf5W1hIiInoDAWXwgGHS9uq+Vnr+3m7T0NZKQmcftFk7j1giLGZw33ujwRkZNSGEtMO9wd4Mm1lTz0+h5217czIWs4X7t2Jh8+r4AMTVMpIjFCYSwxqbmjh1++uZeH39hLQ3s3c/NH8qMb53PNOWNJ0vVgEYkxCmOJKbWtnfz363t45K39tHX18q7pefzDpVNYNClbc0WLSMxSGEtMqGjo4IFXd/NYWQW9gSDXzh3Ppy6dwqzxmV6XJiJy1hTGMqTtrGnlxy/v4g/rD5Bg8P4F+Xzy0ilMyk33ujQRkahRGMuQtL6iif96uZxnN9cwPDmRWy8o4hMXT2LcSI2MFhH/URjLkFK2t4EfvriT13bWkzksiX9cWsytFxTp0YUi4msKYxkS1uxr5D9e2MFrO+vJHZHCPVfP4COLC3V7kojEBYWxeOqd/Y384IWdvLqjjpz0FL5yzQxuPn8iaSk6NEUkfugbTzyxvqKJH7ywg5e315GdHjoT/tgShbCIxKeIvvnMbBnwQyAReNA5961+9vkQcC/ggPXOuZuiWKf4xOYDzXz/uR28uK2WrLRkvrhsOrcsKSI9VSEsIvHrlN+AZpYI3A9cAVQCpWa20jm3pc8+xcCXgQudc41mNnqgCpbYtLe+ne8/v4OV6w8wcngyX7hqOrdcUMQIhbCISERnxouAcufcbgAzexS4HtjSZ5+/B+53zjUCOOdqo12oxKaalk5+9OJOHiutIDkxgc+8aworLpnCyOEamCUickQkYTwBqOizXAksPm6faQBm9ldCXdn3OueeOf4XmdkKYAVAYWHhmdQrMaK5o4efvLqLh/+6h96A48ZFhdz57qmMzhzmdWkiIkNOtPoIk4Bi4DIgH3jVzOY455r67uScewB4AKCkpMRF6b1lCDncHeDhN/bwk5d30drVy/XnjudzV0xjYo5mzBIROZFIwrgKKOiznB9e11clsNo51wPsMbMdhMK5NCpVypDXGwjyWFkFP3xhJ7WtXSydMZrPXzWdmeM0d7SIyKlEEsalQLGZTSIUwsuB40dK/x64EXjYzHIJdVvvjmKdMkQ553h5Rx3/9uet7Kxto2TiKO7/yALOK8r2ujQRkZhxyjB2zvWa2R3As4SuBz/knNtsZvcBZc65leFtV5rZFiAAfME5d2ggCxfvba1u4Zt/3srr5fUU5aTxk5sXcNXssXqUoYjIaTLnvLl0W1JS4srKyjx5bzk7NS2dfP+5HTy+poLMYcnctbSYm8+fSEpSgteliYgMWWa2xjlX0t823eQpEevo7uWBV3fz01d20xsMcvuFk7jz3cWMTNNtSiIiZ0NhLKcUDDqeXFvJ/31uOzUtXVwzZyxfWjZDI6RFRKJEYSwnta6iiW/8YRPrK5uZV5DF/TctoESDs0REokphLP061NbFd57ZzmNlFYzOSOUHHz6XG+ZN0OAsEZEBoDCWY/QGgjyyej/fe247Hd0BPnnJZO5cWqw5pEVEBpC+YeWo9RVNfPmpjWypbuHi4ly+8Z7ZTB09wuuyRER8T2EstHb28L3ndvCLN/cyOiOVH39kAcvO0f3CIiKDRWEcx5xzPLv5IN9YuZna1i5uWVLE3VdOI2OYblUSERlMCuM4VdV0mG/8YRMvbK1l1rhMfvrREuYVZHldlohIXFIYx5lg0PGrt/bx7We24Rx89ZqZ3HZhEUmJmj1LRMQrCuM4sv9QB194Yj2r9zRw6bQ8vvnec8gfleZ1WSIicU9hHAeCQcevV+/jW09vI9GM77x/Lh8sydcALRGRIUJh7HP7D3XwxSfX89buBi6Zlse33jeH8VnDvS5LRET6UBj7lHOOX7+1j38Pnw1/+/1z+FBJgc6GRUSGIIWxD9W0dPKFJzbw6o46nQ2LiMQAhbHPPLOpmi8/tZHDPQH+9YZz+MjiQp0Ni4gMcQpjn2jr6uVfVm7md2sqmTNhJP+xfB5T8jSVpYhILFAY+8Da/Y189tF1VDZ2cMe7pnLX5cUk675hEZGYoTCOYcGg48HXd/OdZ7YzduQwHvvkEs7Ts4ZFRGKOwjhGNbZ38/nfrefFbbUsmz2Wb39gLiOHa05pEZFYpDCOQWv2NXLnb9ZS19bFve+ZxS0XFGmQlohIDFMYxxDnHD97LdQtPS5rGE9+6gLm5md5XZaIiJwlhXGMaO/q5YtPbODPG6vVLS0i4jMK4xiw71A7n/zVGnbUtHLP1TP45CWT1S0tIuIjCuMh7pUddfzjb98B4Oe3LeKSaXkeVyQiItGmMB7CHlm9j3/+/Samjcngpx9dyMScdK9LEhGRAaAwHoKcc3z/+R38v5fKedf0PP7zpgWkp+p/lYiIX+kbfojpCQT5ylMb+d2aSj5cUsA333sOSZpNS0TE1xTGQ0h7Vy+ffmQtr+yo466lxXz28mIN1BIRiQMK4yGirrWLj/+8lC3VLXzrfXNYvqjQ65JERGSQKIyHgD317dzy0NvUtnbywEcXsnTmGK9LEhGRQaQw9tjW6hZufnA1Dvjt35/P/MJRXpckIiKDTGHsoQ2VTXzsobcZnpzII59YzGQ9f1hEJC4pjD2yZl8Dtz5Uysi0ZH779+dTkJ3mdUkiIuKRiO6ZMbNlZrbdzMrN7J5+tt9qZnVmti7884nol+ofb+46xEf/+21yM1J5/JNLFMQiInHulGfGZpYI3A9cAVQCpWa20jm35bhdH3PO3TEANfpK6d4Gbvv52xSMSuORTyxmdOYwr0sSERGPRXJmvAgod87tds51A48C1w9sWf60qaqZjz9cyvis4fx2xfkKYhERASIL4wlARZ/lyvC6473fzDaY2RNmVhCV6nykvLaVjz30NpnDk/n17YvJHZHqdUkiIjJERGuexT8CRc65ucDzwC/628nMVphZmZmV1dXVRemth76Khg4+8uBqEhOMRz6xmPFZw70uSUREhpBIwrgK6Hummx9ed5Rz7pBzriu8+CCwsL9f5Jx7wDlX4pwrycuLj0cB1rR08pEHV9PVG+TXty+mKFdPXhIRkWNFEsalQLGZTTKzFGA5sLLvDmY2rs/idcDW6JUYuxrbu7n5wdUcauviF7ctYvrYDK9LEhGRIeiUo6mdc71mdgfwLJAIPOSc22xm9wFlzrmVwD+a2XVAL9AA3DqANceErt4AK35Vxr6GDn5x2yLOLcjyuiQRERmizDnnyRuXlJS4srIyT957oDnn+Oxj6/jDugP8503z+bu5470uSUREPGZma5xzJf1t04NyB8APXtjJH9Yd4AtXTVcQi4jIKSmMo+yptZX86MWdfGBhPp++bIrX5YiISAxQGEdR6d4GvvTkBpZMzuHf3jsHM/O6JBERiQEK4yipbenk04+sJX9UGj+5eSEpSWpaERGJjJ7aFAU9gSCf+c1a2jp7+fXtixmZlux1SSIiEkMUxlHw76u2Ubq3kR8un6d7iUVE5LSpL/UsPb+lhof+uodbLyji+nn9TdktIiJycgrjs1DX2sU9T25g1rhMvnLNTK/LERGRGKVu6jPknOOeJzfQ2tXLb5fP04AtERE5Y0qQM/RoaQUvbqvlS8tmMG2MrhOLiMiZUxifgaqmw/zrn7Zw4dQcbrugyOtyREQkximMT5Nzjn/+/SaCDr71vrkkJGhiDxEROTsK49P0pw3VvLStlruvnEZBdprX5YiIiA8ojE9DU0c3//LHzczNH8mt6p4WEZEo0Wjq0/DdZ7fT2NHDLz++mKRE/TtGRESiQ4kSoV11bTxaWsHNiwuZNT7T63JERMRHFMYR+u4z2xmWlMCdS4u9LkVERHxGYRyBtfsbeWbzQVZcMoXcEalelyMiIj6jMD4F5xzfWrWN3BGpfOLiSV6XIyIiPqQwPoVXdtTx9t4G7rq8mPRUjXcTEZHoUxifwn+9vIvxI4fx4ZICr0sRERGfUhifxJp9Dby9p4FPXDxZD4IQEZEBo4Q5iR+/vJustGSWL9JZsYiIDByF8QnsqGnlha013LKkiLQUXSsWEZGBozA+gZ+8sovhyYncomkvRURkgCmM+1HdfJiV6w7w4fMKyE5P8bocERHxOYVxP3791j4CznH7RbqvWEREBp7C+DidPQF+s3o/l88co0ckiojIoFAYH2flugM0dvRw24VFXpciIiJxQmHch3OOh9/Yy/QxGSyZnON1OSIiEicUxn28vaeBrdUt3HZhEWbmdTkiIhInFMZ9/OLNvWSlJXPD/AlelyIiInFEYRxW39bFc5tr+ODCfIYlJ3pdjoiIxBGFcdhTayvpDTo+fJ6mvhQRkcGlMCY0cOux0goWThzF1NEZXpcjIiJxJqIwNrNlZrbdzMrN7J6T7Pd+M3NmVhK9Egfe2v2N7Kpr12MSRUTEE6cMYzNLBO4HrgZmATea2ax+9ssA7gJWR7vIgfZYaQXpKYlcO3ec16WIiEgciuTMeBFQ7pzb7ZzrBh4Fru9nv/8DfBvojGJ9A66tq5c/bajm7+aOJz1VT2cSEZHBF0kYTwAq+ixXhtcdZWYLgALn3J+jWNugWLWhmo7uAB/SwC0REfHIWQ/gMrME4PvA3RHsu8LMysysrK6u7mzfOir+tLGawuw0FhRmeV2KiIjEqUjCuAroe9qYH153RAZwDvCyme0FzgdW9jeIyzn3gHOuxDlXkpeXd+ZVR0lzRw9vlNdz9ZyxmnFLREQ8E0kYlwLFZjbJzFKA5cDKIxudc83OuVznXJFzrgh4C7jOOVc2IBVH0fNba+gNOq45RwO3RETEO6cMY+dcL3AH8CywFXjcObfZzO4zs+sGusCB9PTGaiZkDWdu/kivSxERkTgW0fBh59wqYNVx675+gn0vO/uyBl5rZw+v7azno0smqotaREQ8FbczcL20rZbuQJBr5oz1uhQREYlzcRvGqzZWMyYzlfkFo7wuRURE4lxchnF7Vy8vb69j2eyxJCSoi1pERLwVl2H88vY6unqDXD1Ho6hFRMR7cRnGT2+qJndECucVZXtdioiISPyFcWdPgJe21XLl7LEkqotaRESGgLgL41d21NHRHeDqczSKWkREhoa4C+MXt9aQOSyJ8yfneF2KiIgIEGdh7JzjtZ31XDg1l+TEuProIiIyhMVVIu2qa6e6uZOLinO9LkVEROSouArj13eGHtt4SbH3T4wSERE5Ir7CuLyeiTlpFGSneV2KiIjIUXETxj2BIG/tbuCiqeqiFhGRoSVuwnhdRRNtXb1crOvFIiIyxMRNGL+2s54EgyVTFMYiIjK0xFEY13FuQRYjhyd7XYqIiMgx4iKMmw/3sL6iiYt1vVhERIaguAjjNfsaCDq4QGEsIiJDUFyE8YbKZhIM5kwY6XUpIiIifyNuwnjq6BGkpyZ5XYqIiMjf8H0YO+fYUNnMnAlZXpciIiLSL9+HcXVzJ/VtXczNVxe1iIgMTb4P4w2VzQAKYxERGbJ8H8Ybq5pISjBmjsv0uhQREZF++T6MN1Q2M21MBsOSE70uRUREpF++DuMjg7fOLVAXtYiIDF2+DuP9DR00H+7RSGoRERnSfB3GGrwlIiKxwNdhvLGqmZTEBKaNyfC6FBERkRPydRivr2hi5vhMUpJ8/TFFRCTG+TalnHNsPtDCnAm6pUlERIY234ZxTUsXbV29TFcXtYiIDHG+DeNddW0ATMkb4XElIiIiJ+f7MJ6sMBYRkSHOv2Fc20Z6SiJjMlO9LkVEROSkIgpjM1tmZtvNrNzM7uln+z+Y2UYzW2dmr5vZrOiXenp217czZfQIzMzrUkRERE7qlGFsZonA/cDVwCzgxn7C9jfOuTnOuXnAd4DvR7vQ07Wrtk3Xi0VEJCZEcma8CCh3zu12znUDjwLX993BOdfSZzEdcNEr8fS1d/VyoLmTKXnpXpYhIiISkaQI9pkAVPRZrgQWH7+TmX0G+CcgBXh3f7/IzFYAKwAKCwtPt9aI7alvBzSSWkREYkPUBnA55+53zk0BvgR87QT7POCcK3HOleTl5UXrrf+GRlKLiEgsiSSMq4CCPsv54XUn8ihww1nUdNZ21bWTYDAxJ83LMkRERCISSRiXAsVmNsnMUoDlwMq+O5hZcZ/Fa4Gd0Svx9O2qa6MgO41hyYleliEiIhKRU14zds71mtkdwLNAIvCQc26zmd0HlDnnVgJ3mNnlQA/QCNwykEWfyu66dl0vFhGRmBHJAC6cc6uAVcet+3qf13dFua4zFgw6dte1cdHUHK9LERERiYjvZuCqajpMV29Qg7dERCRm+C6M9YAIERGJNb4L4911R+4x1oQfIiISG3wXxrvq2shKSyY7PcXrUkRERCLiuzA+0HSY/FHD9YAIERGJGb4L44aOHrLT9dhEERGJHb4L46aObrLTkr0uQ0REJGK+C+OG9m5G6XqxiIjEEF+FcU8gSGtnL6PSFMYiIhI7fBXGjR3dADozFhGRmOKvMG7vASBbZ8YiIhJDfBXGDe1Hzow1gEtERGKHr8L4SDe1JvwQEZFY4qswPnpmrG5qERGJIb4K48ZwGGfpPmMREYkh/grjjh5GpCaRmpTodSkiIiIR81kYd2vwloiIxBxfhXFDe7duaxIRkZjjqzAOnRkrjEVEJLb4Kowb2rs1klpERGKOr8K4UWEsIiIxyDdh3N0bpL07oNuaREQk5vgmjDt7AwAMT9ZtTSIiElt8E8bdvUEAUpN985FERCRO+Ca5joRxSqJvPpKIiMQJ3yTX0TBO8s1HEhGROOGb5OpSGIuISIzyTXKpm1pERGKVb5KrOxAaTZ2q0dQiIhJjfBPGXTozFhGRGOWb5NIALhERiVW+Sa6j9xkrjEVEJMb4Jrk0mlpERGKVb5JLo6lFRCRW+Sa5ugOaDlNERGJTRMllZsvMbLuZlZvZPf1s/ycz22JmG8zsRTObGP1ST05nxiIiEqtOmVxmlgjcD1wNzAJuNLNZx+32DlDinJsLPAF8J9qFnopGU4uISKyKJLkWAeXOud3OuW7gUeD6vjs45/7inOsIL74F5Ee3zFM70k2tMBYRkVgTSXJNACr6LFeG153I7cDT/W0wsxVmVmZmZXV1dZFXGYGuntAMXOqmFhGRWBPV5DKzm4ES4Lv9bXfOPeCcK3HOleTl5UXzrekKBElJSsDMovp7RUREBlpSBPtUAQV9lvPD645hZpcDXwUudc51Rae8yHX3BknVWbGIiMSgSNKrFCg2s0lmlgIsB1b23cHM5gM/Ba5zztVGv8xT6+4N6nqxiIjEpFOml3OuF7gDeBbYCjzunNtsZveZ2XXh3b4LjAB+Z2brzGzlCX7dgFEYi4hIrIqkmxrn3Cpg1XHrvt7n9eVRruu0dSmMRUQkRvkmvbp7gxpJLSIiMck36dUdCGoqTBERiUm+SS+dGYuISKzyTXppAJeIiMQq36RXaNKPRK/LEBEROW3+CeOegLqpRUQkJvkmvTSAS0REYpVv0kvTYYqISKzyTXppAJeIiMQq36RXd0BhLCIisck36dXVo/uMRUQkNvkmvTSAS0REYpUv0isQdASCjpRE3WcsIiKxxxdh3N0bBNA1YxERiUm+SC+FsYiIxDJfpFdXIAAojEVEJDb5Ir26ekJnxpr0Q0REYpEv0qs7EA5jjaYWEZEY5Iv0OnrNWGfGIiISg3yRXhrAJSIiscwX6XWkm1phLCIiscgX6XVkAJe6qUVEJBb5Ir26w7c2pSZrBi4REYk9/ghjDeASEZEY5ov06tIALhERiWG+SK8jZ8apCmMREYlBvkivvIxULi7OJT01yetSRERETpsv0uuy6aO5bPpor8sQERE5I744MxYREYllCmMRERGPKYxFREQ8pjAWERHxmMJYRETEYwpjERERjymMRUREPBZRGJvZMjPbbmblZnZPP9svMbO1ZtZrZh+IfpkiIiL+dcowNrNE4H7gamAWcKOZzTput/3ArcBvol2giIiI30UyA9cioNw5txvAzB4Frge2HNnBObc3vC04ADWKiIj4WiTd1BOAij7LleF1p83MVphZmZmV1dXVncmvEBER8Z1BHcDlnHvAOVfinCvJy8sbzLcWEREZsiIJ4yqgoM9yfnidiIiIREEk14xLgWIzm0QohJcDN53tG69Zs6bezPad7e/pIxeoj+Lvi3Vqj2OpPY6l9jiW2uNYao9jRas9Jp5ogznnTvlfm9k1wH8AicBDzrlvmtl9QJlzbqWZnQf8DzAK6AQOOudmR6HwiJlZmXOuZDDfcyhTexxL7XEstcex1B7HUnscazDaI6LnGTvnVgGrjlv39T6vSwl1X4uIiMhp0gxcIiIiHvNTGD/gdQFDjNrjWGqPY6k9jqX2OJba41gD3h4RXTMWERGRgeOnM2MREZGY5IswPtWDLOKBme01s41mts7MysLrss3seTPbGf5zlNd1DhQze8jMas1sU591/X5+C/lR+HjZYGYLvKt8YJygPe41s6rwMbIufJfEkW1fDrfHdjO7ypuqB4aZFZjZX8xsi5ltNrO7wuvj8vg4SXvE6/ExzMzeNrP14fb4l/D6SWa2Ovy5HzOzlPD61PByeXh7UVQKcc7F9A+h2612AZOBFGA9MMvrujxoh71A7nHrvgPcE359D/Btr+scwM9/CbAA2HSqzw9cAzwNGHA+sNrr+gepPe4FPt/PvrPCf29SgUnhv0+JXn+GKLbFOGBB+HUGsCP8mePy+DhJe8Tr8WHAiPDrZGB1+P/748Dy8PqfAJ8Kv/408JPw6+XAY9Goww9nxkcfZOGc6waOPMhCQu3wi/DrXwA3eFfKwHLOvQo0HLf6RJ//euCXLuQtIMvMxg1KoYPkBO1xItcDjzrnupxze4ByQn+vfME5V+2cWxt+3QpsJTS/flweHydpjxPx+/HhnHNt4cXk8I8D3g08EV5//PFx5Lh5AlhqZna2dfghjKP2IIsY54DnzGyNma0IrxvjnKsOvz4IjPGmNM+c6PPH8zFzR7jr9aE+ly3ipj3CXYrzCZ39xP3xcVx7QJweH2aWaGbrgFrgeUJn/03Oud7wLn0/89H2CG9vBnLOtgY/hLGEXOScW0DoudOfMbNL+m50oT6VuB06H++fP+zHwBRgHlANfM/TagaZmY0AngQ+65xr6bstHo+Pftojbo8P51zAOTeP0ORVi4AZg12DH8JYD7IAnHNV4T9rCU1NugioOdK9Fv6z1rsKPXGizx+Xx4xzrib8pRMEfsb/djX6vj3MLJlQ8DzinHsqvDpuj4/+2iOej48jnHNNwF+AJYQuTxyZpbLvZz7aHuHtI4FDZ/vefgjjow+yCI92Ww6s9LimQWVm6WaWceQ1cCWwiVA73BLe7RbgD95U6JkTff6VwMfCo2bPB5r7dFf61nHXPd9L6BiBUHssD48SnQQUA28Pdn0DJXw977+Brc657/fZFJfHx4naI46Pjzwzywq/Hg5cQeg6+l+AD4R3O/74OHLcfAB4Kdyzcna8HskWjR9Cox93EOrn/6rX9Xjw+ScTGu24Hth8pA0IXcd4EdgJvABke13rALbBbwl1rfUQur5z+4k+P6HRk/eHj5eNQInX9Q9Se/wq/Hk3hL9QxvXZ/6vh9tgOXO11/VFui4sIdUFvANaFf66J1+PjJO0Rr8fHXOCd8OfeBHw9vH4yoX90lAO/A1LD64eFl8vD2ydHow7NwCUiIuIxP3RTi4iIxDSFsYiIiMcUxiIiIh5TGIuIiHhMYSwiIuIxhbGIiIjHFMYiIiIeUxiLiIh47P8DVDHLJ22eGNsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaled_frame = StandardScaler().fit_transform(features.values)\n",
    "pc1 = PCA(n_components=300)\n",
    "pc1.fit(scaled_frame)\n",
    "\n",
    "plt.plot(np.cumsum(pc1.explained_variance_ratio_))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalComponents = pc1.fit_transform(scaled_frame)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = [np.arange(0,300)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82.338075</td>\n",
       "      <td>-73.611379</td>\n",
       "      <td>3.906973</td>\n",
       "      <td>33.819354</td>\n",
       "      <td>-59.354301</td>\n",
       "      <td>10.714485</td>\n",
       "      <td>-10.008898</td>\n",
       "      <td>-12.371845</td>\n",
       "      <td>-12.643462</td>\n",
       "      <td>-5.358708</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.359748</td>\n",
       "      <td>0.353290</td>\n",
       "      <td>-1.929619</td>\n",
       "      <td>-2.083834</td>\n",
       "      <td>0.564526</td>\n",
       "      <td>-0.168729</td>\n",
       "      <td>1.693076</td>\n",
       "      <td>-1.128616</td>\n",
       "      <td>2.221298</td>\n",
       "      <td>0.911180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-80.037709</td>\n",
       "      <td>-59.489853</td>\n",
       "      <td>4.667732</td>\n",
       "      <td>3.106723</td>\n",
       "      <td>-9.462458</td>\n",
       "      <td>-3.049594</td>\n",
       "      <td>-6.432534</td>\n",
       "      <td>6.352022</td>\n",
       "      <td>22.752971</td>\n",
       "      <td>11.662656</td>\n",
       "      <td>...</td>\n",
       "      <td>19.684380</td>\n",
       "      <td>19.619637</td>\n",
       "      <td>2.812831</td>\n",
       "      <td>20.423266</td>\n",
       "      <td>-26.227645</td>\n",
       "      <td>13.520661</td>\n",
       "      <td>-24.420083</td>\n",
       "      <td>-5.830231</td>\n",
       "      <td>-25.687996</td>\n",
       "      <td>-10.006315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.019354</td>\n",
       "      <td>-73.784219</td>\n",
       "      <td>-1.418993</td>\n",
       "      <td>18.331087</td>\n",
       "      <td>-11.174846</td>\n",
       "      <td>-8.784098</td>\n",
       "      <td>-22.167719</td>\n",
       "      <td>15.057054</td>\n",
       "      <td>16.430602</td>\n",
       "      <td>1.913122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134007</td>\n",
       "      <td>-5.881490</td>\n",
       "      <td>1.889430</td>\n",
       "      <td>-2.766399</td>\n",
       "      <td>-0.446235</td>\n",
       "      <td>-1.893521</td>\n",
       "      <td>2.970106</td>\n",
       "      <td>-3.396570</td>\n",
       "      <td>1.901833</td>\n",
       "      <td>2.269406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.712661</td>\n",
       "      <td>-64.291802</td>\n",
       "      <td>-3.171556</td>\n",
       "      <td>9.458681</td>\n",
       "      <td>-12.060785</td>\n",
       "      <td>-9.137764</td>\n",
       "      <td>-12.411651</td>\n",
       "      <td>13.648088</td>\n",
       "      <td>20.055473</td>\n",
       "      <td>1.731157</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151662</td>\n",
       "      <td>-1.324503</td>\n",
       "      <td>0.051812</td>\n",
       "      <td>-0.377841</td>\n",
       "      <td>-0.354902</td>\n",
       "      <td>-0.255213</td>\n",
       "      <td>1.146378</td>\n",
       "      <td>-0.104843</td>\n",
       "      <td>1.264373</td>\n",
       "      <td>0.713166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-79.718590</td>\n",
       "      <td>-63.798879</td>\n",
       "      <td>-2.096706</td>\n",
       "      <td>-3.378497</td>\n",
       "      <td>-4.321059</td>\n",
       "      <td>-7.948347</td>\n",
       "      <td>-5.033225</td>\n",
       "      <td>14.805149</td>\n",
       "      <td>26.897691</td>\n",
       "      <td>2.094620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167028</td>\n",
       "      <td>-1.585920</td>\n",
       "      <td>-0.521415</td>\n",
       "      <td>1.379437</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.012859</td>\n",
       "      <td>0.723052</td>\n",
       "      <td>0.290565</td>\n",
       "      <td>-0.403811</td>\n",
       "      <td>0.040360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>-77.169521</td>\n",
       "      <td>12.232554</td>\n",
       "      <td>-3.341187</td>\n",
       "      <td>-24.527092</td>\n",
       "      <td>9.516145</td>\n",
       "      <td>5.074522</td>\n",
       "      <td>-5.616899</td>\n",
       "      <td>-2.246240</td>\n",
       "      <td>-3.505061</td>\n",
       "      <td>-1.370361</td>\n",
       "      <td>...</td>\n",
       "      <td>1.239742</td>\n",
       "      <td>1.649279</td>\n",
       "      <td>-0.303758</td>\n",
       "      <td>-0.611951</td>\n",
       "      <td>1.417519</td>\n",
       "      <td>-1.923835</td>\n",
       "      <td>0.983783</td>\n",
       "      <td>-0.529663</td>\n",
       "      <td>-1.211192</td>\n",
       "      <td>1.129476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>-47.469077</td>\n",
       "      <td>35.129839</td>\n",
       "      <td>2.032567</td>\n",
       "      <td>23.816386</td>\n",
       "      <td>5.127484</td>\n",
       "      <td>-12.737335</td>\n",
       "      <td>0.392818</td>\n",
       "      <td>27.018781</td>\n",
       "      <td>-30.507060</td>\n",
       "      <td>1.977007</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.438062</td>\n",
       "      <td>0.377106</td>\n",
       "      <td>0.560463</td>\n",
       "      <td>-1.751437</td>\n",
       "      <td>-1.973689</td>\n",
       "      <td>0.868432</td>\n",
       "      <td>-0.392356</td>\n",
       "      <td>3.717804</td>\n",
       "      <td>-2.593810</td>\n",
       "      <td>1.809789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>-64.664697</td>\n",
       "      <td>20.831303</td>\n",
       "      <td>-5.207723</td>\n",
       "      <td>5.324640</td>\n",
       "      <td>-0.854015</td>\n",
       "      <td>-9.822544</td>\n",
       "      <td>4.231098</td>\n",
       "      <td>20.382853</td>\n",
       "      <td>-8.749984</td>\n",
       "      <td>6.452395</td>\n",
       "      <td>...</td>\n",
       "      <td>1.806956</td>\n",
       "      <td>0.276549</td>\n",
       "      <td>0.746862</td>\n",
       "      <td>0.492849</td>\n",
       "      <td>4.013242</td>\n",
       "      <td>0.965943</td>\n",
       "      <td>-0.475948</td>\n",
       "      <td>-1.561320</td>\n",
       "      <td>-2.405458</td>\n",
       "      <td>2.324061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>-71.870654</td>\n",
       "      <td>14.319836</td>\n",
       "      <td>-3.427867</td>\n",
       "      <td>-21.076400</td>\n",
       "      <td>1.207770</td>\n",
       "      <td>1.721152</td>\n",
       "      <td>-0.624263</td>\n",
       "      <td>-5.424939</td>\n",
       "      <td>3.125115</td>\n",
       "      <td>-6.629747</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.249995</td>\n",
       "      <td>-1.247170</td>\n",
       "      <td>-0.825729</td>\n",
       "      <td>0.820561</td>\n",
       "      <td>1.185411</td>\n",
       "      <td>-0.268257</td>\n",
       "      <td>2.993283</td>\n",
       "      <td>2.388837</td>\n",
       "      <td>-0.084309</td>\n",
       "      <td>-0.522818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>-78.123873</td>\n",
       "      <td>20.976309</td>\n",
       "      <td>4.350558</td>\n",
       "      <td>-9.126756</td>\n",
       "      <td>-2.428350</td>\n",
       "      <td>-15.032184</td>\n",
       "      <td>15.422890</td>\n",
       "      <td>12.850247</td>\n",
       "      <td>-5.604312</td>\n",
       "      <td>22.948753</td>\n",
       "      <td>...</td>\n",
       "      <td>1.299113</td>\n",
       "      <td>0.932779</td>\n",
       "      <td>-0.909313</td>\n",
       "      <td>1.516211</td>\n",
       "      <td>0.517714</td>\n",
       "      <td>-1.649771</td>\n",
       "      <td>-0.704732</td>\n",
       "      <td>-0.416274</td>\n",
       "      <td>0.570040</td>\n",
       "      <td>0.408112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>965 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1         2          3          4          5    \\\n",
       "0    82.338075 -73.611379  3.906973  33.819354 -59.354301  10.714485   \n",
       "1   -80.037709 -59.489853  4.667732   3.106723  -9.462458  -3.049594   \n",
       "2     8.019354 -73.784219 -1.418993  18.331087 -11.174846  -8.784098   \n",
       "3   -44.712661 -64.291802 -3.171556   9.458681 -12.060785  -9.137764   \n",
       "4   -79.718590 -63.798879 -2.096706  -3.378497  -4.321059  -7.948347   \n",
       "..         ...        ...       ...        ...        ...        ...   \n",
       "960 -77.169521  12.232554 -3.341187 -24.527092   9.516145   5.074522   \n",
       "961 -47.469077  35.129839  2.032567  23.816386   5.127484 -12.737335   \n",
       "962 -64.664697  20.831303 -5.207723   5.324640  -0.854015  -9.822544   \n",
       "963 -71.870654  14.319836 -3.427867 -21.076400   1.207770   1.721152   \n",
       "964 -78.123873  20.976309  4.350558  -9.126756  -2.428350 -15.032184   \n",
       "\n",
       "           6          7          8          9    ...        290        291  \\\n",
       "0   -10.008898 -12.371845 -12.643462  -5.358708  ...  -5.359748   0.353290   \n",
       "1    -6.432534   6.352022  22.752971  11.662656  ...  19.684380  19.619637   \n",
       "2   -22.167719  15.057054  16.430602   1.913122  ...   0.134007  -5.881490   \n",
       "3   -12.411651  13.648088  20.055473   1.731157  ...  -0.151662  -1.324503   \n",
       "4    -5.033225  14.805149  26.897691   2.094620  ...   0.167028  -1.585920   \n",
       "..         ...        ...        ...        ...  ...        ...        ...   \n",
       "960  -5.616899  -2.246240  -3.505061  -1.370361  ...   1.239742   1.649279   \n",
       "961   0.392818  27.018781 -30.507060   1.977007  ...  -1.438062   0.377106   \n",
       "962   4.231098  20.382853  -8.749984   6.452395  ...   1.806956   0.276549   \n",
       "963  -0.624263  -5.424939   3.125115  -6.629747  ...  -1.249995  -1.247170   \n",
       "964  15.422890  12.850247  -5.604312  22.948753  ...   1.299113   0.932779   \n",
       "\n",
       "          292        293        294        295        296       297  \\\n",
       "0   -1.929619  -2.083834   0.564526  -0.168729   1.693076 -1.128616   \n",
       "1    2.812831  20.423266 -26.227645  13.520661 -24.420083 -5.830231   \n",
       "2    1.889430  -2.766399  -0.446235  -1.893521   2.970106 -3.396570   \n",
       "3    0.051812  -0.377841  -0.354902  -0.255213   1.146378 -0.104843   \n",
       "4   -0.521415   1.379437   0.697810   0.012859   0.723052  0.290565   \n",
       "..        ...        ...        ...        ...        ...       ...   \n",
       "960 -0.303758  -0.611951   1.417519  -1.923835   0.983783 -0.529663   \n",
       "961  0.560463  -1.751437  -1.973689   0.868432  -0.392356  3.717804   \n",
       "962  0.746862   0.492849   4.013242   0.965943  -0.475948 -1.561320   \n",
       "963 -0.825729   0.820561   1.185411  -0.268257   2.993283  2.388837   \n",
       "964 -0.909313   1.516211   0.517714  -1.649771  -0.704732 -0.416274   \n",
       "\n",
       "           298        299  \n",
       "0     2.221298   0.911180  \n",
       "1   -25.687996 -10.006315  \n",
       "2     1.901833   2.269406  \n",
       "3     1.264373   0.713166  \n",
       "4    -0.403811   0.040360  \n",
       "..         ...        ...  \n",
       "960  -1.211192   1.129476  \n",
       "961  -2.593810   1.809789  \n",
       "962  -2.405458   2.324061  \n",
       "963  -0.084309  -0.522818  \n",
       "964   0.570040   0.408112  \n",
       "\n",
       "[965 rows x 300 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principalDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for any high correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_mat = principalDf.iloc[:,:-1].corr().abs()\n",
    "# corr_thresh = 0.75\n",
    "# for i in range(c_mat.shape[0]):\n",
    "#     for j in range(i+1, c_mat.shape[1]):\n",
    "#         if c_mat.iloc[i,j] > corr_thresh:\n",
    "#             print(f'Thresh reached for ({c_mat.index[i]}, {c_mat.columns[j]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Should we try a combination of clustering based on groups(A,B,C...) and regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = principalDf \n",
    "y_train = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7348.226389817379\n"
     ]
    }
   ],
   "source": [
    "### Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "clf = LinearRegression()\n",
    "scores = cross_validate(clf, X_train, y_train, cv=5, scoring=['neg_mean_squared_error'])['test_neg_mean_squared_error']\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16481.66966545859, tolerance: 13.037395336787563\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10590.715562761452, tolerance: 13.118487435233154\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16912.966550026606, tolerance: 14.345858419689115\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10957.243594002462, tolerance: 13.848785880829007\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5657.183363536191, tolerance: 13.037395336787563\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4325.066008478549, tolerance: 13.118487435233154\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9049.084950010129, tolerance: 14.345858419689115\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4009.8308016082883, tolerance: 13.848785880829007\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3252.7210941624144, tolerance: 13.037395336787563\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1793.8236025644364, tolerance: 13.118487435233154\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4771.810954216075, tolerance: 14.345858419689115\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 480.37053242437105, tolerance: 13.848785880829007\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1734.1374744226268, tolerance: 13.037395336787563\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 756.8813833324748, tolerance: 13.118487435233154\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2024.2089486699042, tolerance: 14.345858419689115\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 156.82791743900452, tolerance: 13.848785880829007\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 951.7856051629788, tolerance: 13.037395336787563\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 336.6208286056717, tolerance: 13.118487435233154\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 632.0154611378384, tolerance: 14.345858419689115\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 238.10664156726853, tolerance: 13.848785880829007\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 554.9672237137202, tolerance: 13.037395336787563\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 205.28811947820213, tolerance: 13.118487435233154\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 161.51644321901404, tolerance: 14.345858419689115\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 248.85462749120052, tolerance: 13.848785880829007\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193.8391021481657, tolerance: 13.037395336787563\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 79.57092068041675, tolerance: 13.118487435233154\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 649.6608827784876, tolerance: 14.345858419689115\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.889674524907605, tolerance: 13.848785880829007\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.2958703702534, tolerance: 13.037395336787563\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.560458119551186, tolerance: 13.118487435233154\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 102.96088660600071, tolerance: 14.345858419689115\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.141206968917686, tolerance: 13.848785880829007\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 103.78847325319657, tolerance: 13.037395336787563\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 67.97717713586462, tolerance: 13.118487435233154\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 83.75131510065694, tolerance: 13.848785880829007\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28.218756681853847, tolerance: 13.037395336787563\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20.782071927613288, tolerance: 13.118487435233154\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 66.97557587216579, tolerance: 13.848785880829007\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 71.09674418808572, tolerance: 13.037395336787563\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14.646543827519054, tolerance: 13.118487435233154\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63.37171630584635, tolerance: 13.848785880829007\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 84.70714727128507, tolerance: 13.037395336787563\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.84743633735343, tolerance: 13.848785880829007\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51.76335846623988, tolerance: 13.037395336787563\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 247.60965251723974, tolerance: 14.345858419689115\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27.523016029219434, tolerance: 13.037395336787563\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 135.12738392660685, tolerance: 14.345858419689115\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21.843064356042305, tolerance: 13.037395336787563\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 54.73324471604428, tolerance: 14.345858419689115\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 25.776342504876084, tolerance: 13.848785880829007\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.89422525202099, tolerance: 14.345858419689115\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23.890288470669475, tolerance: 13.848785880829007\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.70878833559982, tolerance: 14.345858419689115\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15.69084793249931, tolerance: 13.848785880829007\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16.927906573968357, tolerance: 14.345858419689115\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.39230433243938, tolerance: 14.345858419689115\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 33.446195345743035, tolerance: 14.345858419689115\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26.20121901256789, tolerance: 14.345858419689115\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/software/python3/3.8.1/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17.475637309849844, tolerance: 14.345858419689115\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.89}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Grid Search for Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "parameters = {'alpha': np.arange(0.01, 0.9, 0.01)}\n",
    "clf = GridSearchCV(Lasso(), parameters, scoring='neg_mean_squared_error')\n",
    "clf.fit(X_train, y_train)\n",
    "clf.cv_results_['params'][np.argmax(clf.cv_results_['mean_test_score'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-170.2752019405531"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.linear_model import Lasso\n",
    "clf = Lasso(alpha =0.89 )\n",
    "scores = cross_validate(clf, X_train, y_train, cv=5, scoring=['neg_mean_squared_error'])['test_neg_mean_squared_error']\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 300:171, 450: 177, 800: 166"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 9, 'epsilon': 0.08999999999999998}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "parameters = {'C':np.arange(5,10,1), 'epsilon':np.arange(0.01,0.1,0.02)}\n",
    "clf = GridSearchCV(SVR(), parameters, scoring='neg_mean_squared_error')\n",
    "clf.fit(X_train, y_train)\n",
    "clf.cv_results_['params'][np.argmax(clf.cv_results_['mean_test_score'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-153.30419352522338"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "clf = SVR(C= 9, epsilon = 0.01)\n",
    "scores = cross_validate(clf, X_train, y_train, cv=5, scoring=['neg_mean_squared_error'])['test_neg_mean_squared_error']\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 450: 152.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "base_model = RandomForestRegressor(n_estimators = 100, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-148.22067046632122"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New random forest with only the two most important variables\n",
    "model = base_model \n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "scores = cross_validate(model, X_train, y_train, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "np.mean(scores.get('test_score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [100, 110, 120,130],\n",
    "    'max_features': [1,2, 3],\n",
    "    'min_samples_leaf': [1,2,3, 4, 5],\n",
    "    'min_samples_split': [5,6,7, 8],\n",
    "    'n_estimators': [50, 100, 200]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 150 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done 353 tasks      | elapsed:   54.1s\n",
      "[Parallel(n_jobs=-1)]: Done 636 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 864 out of 864 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 110,\n",
       " 'max_features': 2,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-169.48566364005805"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = grid_search.best_estimator_\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "scores = cross_validate(model, X_train, y_train, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "np.mean(scores.get('test_score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "300: -145.82, 450: 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(965, 300)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import FactorAnalysis\n",
    "transformer = FactorAnalysis(n_components=300, random_state=0)\n",
    "X_transformed = transformer.fit_transform(features)\n",
    "X_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-146.0891317098446"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "base_model = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "model = base_model \n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "scores = cross_validate(model, X_transformed, y_train, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "np.mean(scores.get('test_score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'~/Hackathon-Summer-2021/test_data/test_expression.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000000003.14</th>\n",
       "      <th>ENSG00000000005.5</th>\n",
       "      <th>ENSG00000000419.12</th>\n",
       "      <th>ENSG00000000457.13</th>\n",
       "      <th>ENSG00000000460.16</th>\n",
       "      <th>ENSG00000000938.12</th>\n",
       "      <th>ENSG00000000971.15</th>\n",
       "      <th>ENSG00000001036.13</th>\n",
       "      <th>ENSG00000001084.10</th>\n",
       "      <th>ENSG00000001167.14</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000283690.1</th>\n",
       "      <th>ENSG00000283691.1</th>\n",
       "      <th>ENSG00000283692.1</th>\n",
       "      <th>ENSG00000283693.1</th>\n",
       "      <th>ENSG00000283694.1</th>\n",
       "      <th>ENSG00000283695.1</th>\n",
       "      <th>ENSG00000283696.1</th>\n",
       "      <th>ENSG00000283697.1</th>\n",
       "      <th>ENSG00000283698.1</th>\n",
       "      <th>ENSG00000283699.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>216130</td>\n",
       "      <td>3724</td>\n",
       "      <td>158501</td>\n",
       "      <td>169431</td>\n",
       "      <td>72136</td>\n",
       "      <td>239413</td>\n",
       "      <td>1958773</td>\n",
       "      <td>405054</td>\n",
       "      <td>190105</td>\n",
       "      <td>111787</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>2382</td>\n",
       "      <td>11417</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>196089</td>\n",
       "      <td>671</td>\n",
       "      <td>96434</td>\n",
       "      <td>112703</td>\n",
       "      <td>67922</td>\n",
       "      <td>15916</td>\n",
       "      <td>209234</td>\n",
       "      <td>105360</td>\n",
       "      <td>192348</td>\n",
       "      <td>110960</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1895</td>\n",
       "      <td>10016</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>455669</td>\n",
       "      <td>123617</td>\n",
       "      <td>217274</td>\n",
       "      <td>174936</td>\n",
       "      <td>88070</td>\n",
       "      <td>382592</td>\n",
       "      <td>817841</td>\n",
       "      <td>396940</td>\n",
       "      <td>397913</td>\n",
       "      <td>198589</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2710</td>\n",
       "      <td>9278</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92006</td>\n",
       "      <td>400</td>\n",
       "      <td>271295</td>\n",
       "      <td>444488</td>\n",
       "      <td>242673</td>\n",
       "      <td>50198</td>\n",
       "      <td>359611</td>\n",
       "      <td>310289</td>\n",
       "      <td>783368</td>\n",
       "      <td>753853</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>544</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>52</td>\n",
       "      <td>6067</td>\n",
       "      <td>27156</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>311516</td>\n",
       "      <td>108041</td>\n",
       "      <td>143606</td>\n",
       "      <td>134343</td>\n",
       "      <td>70622</td>\n",
       "      <td>261239</td>\n",
       "      <td>1046396</td>\n",
       "      <td>238826</td>\n",
       "      <td>187343</td>\n",
       "      <td>172348</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>238</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>5699</td>\n",
       "      <td>5548</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>296204</td>\n",
       "      <td>79196</td>\n",
       "      <td>136213</td>\n",
       "      <td>108992</td>\n",
       "      <td>51934</td>\n",
       "      <td>151602</td>\n",
       "      <td>1306539</td>\n",
       "      <td>282481</td>\n",
       "      <td>296760</td>\n",
       "      <td>99096</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1814</td>\n",
       "      <td>2127</td>\n",
       "      <td>88</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>132013</td>\n",
       "      <td>300</td>\n",
       "      <td>180121</td>\n",
       "      <td>228193</td>\n",
       "      <td>125795</td>\n",
       "      <td>75226</td>\n",
       "      <td>558261</td>\n",
       "      <td>1906351</td>\n",
       "      <td>335050</td>\n",
       "      <td>248454</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>8154</td>\n",
       "      <td>8047</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>310207</td>\n",
       "      <td>124793</td>\n",
       "      <td>118259</td>\n",
       "      <td>91054</td>\n",
       "      <td>43694</td>\n",
       "      <td>142288</td>\n",
       "      <td>504706</td>\n",
       "      <td>315608</td>\n",
       "      <td>275643</td>\n",
       "      <td>84314</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>235</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1355</td>\n",
       "      <td>4441</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>471442</td>\n",
       "      <td>35793</td>\n",
       "      <td>405090</td>\n",
       "      <td>663404</td>\n",
       "      <td>664431</td>\n",
       "      <td>65907</td>\n",
       "      <td>172527</td>\n",
       "      <td>513408</td>\n",
       "      <td>326845</td>\n",
       "      <td>1133083</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>711</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>6726</td>\n",
       "      <td>10172</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>284691</td>\n",
       "      <td>1</td>\n",
       "      <td>205887</td>\n",
       "      <td>315314</td>\n",
       "      <td>192326</td>\n",
       "      <td>14586</td>\n",
       "      <td>51682</td>\n",
       "      <td>489098</td>\n",
       "      <td>341027</td>\n",
       "      <td>380360</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1179</td>\n",
       "      <td>9642</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>965 rows Ã— 52935 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ENSG00000000003.14  ENSG00000000005.5  ENSG00000000419.12  \\\n",
       "0                216130               3724              158501   \n",
       "1                196089                671               96434   \n",
       "2                455669             123617              217274   \n",
       "3                 92006                400              271295   \n",
       "4                311516             108041              143606   \n",
       "..                  ...                ...                 ...   \n",
       "960              296204              79196              136213   \n",
       "961              132013                300              180121   \n",
       "962              310207             124793              118259   \n",
       "963              471442              35793              405090   \n",
       "964              284691                  1              205887   \n",
       "\n",
       "     ENSG00000000457.13  ENSG00000000460.16  ENSG00000000938.12  \\\n",
       "0                169431               72136              239413   \n",
       "1                112703               67922               15916   \n",
       "2                174936               88070              382592   \n",
       "3                444488              242673               50198   \n",
       "4                134343               70622              261239   \n",
       "..                  ...                 ...                 ...   \n",
       "960              108992               51934              151602   \n",
       "961              228193              125795               75226   \n",
       "962               91054               43694              142288   \n",
       "963              663404              664431               65907   \n",
       "964              315314              192326               14586   \n",
       "\n",
       "     ENSG00000000971.15  ENSG00000001036.13  ENSG00000001084.10  \\\n",
       "0               1958773              405054              190105   \n",
       "1                209234              105360              192348   \n",
       "2                817841              396940              397913   \n",
       "3                359611              310289              783368   \n",
       "4               1046396              238826              187343   \n",
       "..                  ...                 ...                 ...   \n",
       "960             1306539              282481              296760   \n",
       "961              558261             1906351              335050   \n",
       "962              504706              315608              275643   \n",
       "963              172527              513408              326845   \n",
       "964               51682              489098              341027   \n",
       "\n",
       "     ENSG00000001167.14  ...  ENSG00000283690.1  ENSG00000283691.1  \\\n",
       "0                111787  ...                  1                160   \n",
       "1                110960  ...                  0                186   \n",
       "2                198589  ...                  0                 71   \n",
       "3                753853  ...                  1                544   \n",
       "4                172348  ...                  0                238   \n",
       "..                  ...  ...                ...                ...   \n",
       "960               99096  ...                  0                 34   \n",
       "961              248454  ...                  1                178   \n",
       "962               84314  ...                  0                235   \n",
       "963             1133083  ...                  0                711   \n",
       "964              380360  ...                  1                251   \n",
       "\n",
       "     ENSG00000283692.1  ENSG00000283693.1  ENSG00000283694.1  \\\n",
       "0                    0                151                 23   \n",
       "1                    0                  1                  0   \n",
       "2                    1                  0                  0   \n",
       "3                    1                  1                 59   \n",
       "4                  152                  0                  0   \n",
       "..                 ...                ...                ...   \n",
       "960                  0                  0                  0   \n",
       "961                  2                  0                 50   \n",
       "962                  1                  0                  0   \n",
       "963                  2                  0                 19   \n",
       "964                  0                  2                  0   \n",
       "\n",
       "     ENSG00000283695.1  ENSG00000283696.1  ENSG00000283697.1  \\\n",
       "0                    2               2382              11417   \n",
       "1                    0               1895              10016   \n",
       "2                    1               2710               9278   \n",
       "3                   52               6067              27156   \n",
       "4                   52               5699               5548   \n",
       "..                 ...                ...                ...   \n",
       "960                  0               1814               2127   \n",
       "961                  1               8154               8047   \n",
       "962                  1               1355               4441   \n",
       "963                  1               6726              10172   \n",
       "964                  0               1179               9642   \n",
       "\n",
       "     ENSG00000283698.1  ENSG00000283699.1  \n",
       "0                    1                  1  \n",
       "1                   48                  0  \n",
       "2                    1                  0  \n",
       "3                   28                  1  \n",
       "4                   76                  1  \n",
       "..                 ...                ...  \n",
       "960                 88                  8  \n",
       "961                 47                  0  \n",
       "962                  1                  0  \n",
       "963                 50                  0  \n",
       "964                  2                  0  \n",
       "\n",
       "[965 rows x 52935 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(965, 300)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import FactorAnalysis\n",
    "transformer = FactorAnalysis(n_components=300, random_state=0)\n",
    "X_test = transformer.fit_transform(test_features)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([55.09, 54.92, 51.28, 51.13, 54.68, 46.41, 56.89, 51.1 , 57.55,\n",
       "       50.53, 59.01, 56.82, 55.72, 62.96, 59.81, 57.33, 54.26, 51.61,\n",
       "       50.9 , 49.42, 43.77, 52.25, 53.64, 52.96, 45.59, 48.29, 56.77,\n",
       "       50.39, 57.95, 56.34, 54.04, 49.84, 53.38, 52.03, 58.88, 53.88,\n",
       "       48.5 , 58.18, 57.31, 49.3 , 50.08, 48.21, 53.13, 54.8 , 49.81,\n",
       "       57.82, 45.5 , 54.41, 52.49, 58.97, 53.96, 56.09, 55.42, 53.85,\n",
       "       47.91, 55.91, 55.51, 50.24, 57.51, 45.86, 58.93, 56.1 , 53.91,\n",
       "       45.2 , 48.48, 56.75, 56.3 , 56.8 , 57.26, 56.49, 49.86, 56.39,\n",
       "       55.7 , 58.1 , 55.76, 51.4 , 50.99, 53.85, 50.99, 55.29, 43.84,\n",
       "       46.15, 52.31, 59.97, 53.71, 58.43, 53.13, 47.59, 55.2 , 52.74,\n",
       "       53.92, 55.45, 50.44, 48.05, 52.16, 43.54, 57.28, 49.44, 49.51,\n",
       "       57.07, 50.84, 54.43, 45.74, 56.38, 52.88, 56.06, 53.83, 52.35,\n",
       "       62.04, 56.79, 50.71, 56.83, 53.87, 55.31, 56.79, 54.63, 57.64,\n",
       "       52.45, 55.22, 54.34, 55.46, 54.02, 58.01, 52.77, 51.37, 55.57,\n",
       "       58.91, 44.17, 52.77, 58.49, 47.  , 55.27, 55.62, 48.21, 56.36,\n",
       "       55.92, 58.27, 60.93, 50.2 , 52.01, 51.09, 48.66, 48.81, 57.55,\n",
       "       54.33, 57.49, 55.59, 49.64, 56.36, 54.64, 51.36, 52.15, 47.06,\n",
       "       51.7 , 49.29, 56.22, 51.33, 58.73, 49.42, 57.83, 53.97, 51.18,\n",
       "       52.89, 60.41, 55.34, 52.26, 56.29, 58.03, 50.38, 58.94, 50.3 ,\n",
       "       52.65, 53.44, 55.64, 56.87, 55.76, 61.08, 53.32, 59.96, 42.3 ,\n",
       "       44.59, 54.8 , 54.44, 59.86, 60.21, 58.33, 54.52, 59.25, 63.28,\n",
       "       54.83, 58.37, 53.74, 51.57, 50.32, 58.02, 52.08, 54.24, 49.62,\n",
       "       51.65, 55.73, 57.43, 50.63, 56.27, 53.32, 54.08, 55.66, 49.17,\n",
       "       53.45, 47.2 , 52.84, 61.8 , 55.21, 57.89, 47.22, 48.94, 54.24,\n",
       "       58.7 , 58.27, 51.85, 57.21, 58.06, 51.61, 53.99, 56.35, 48.33,\n",
       "       54.9 , 52.29, 54.25, 53.1 , 56.35, 51.78, 49.36, 47.53, 56.14,\n",
       "       55.04, 49.04, 46.85, 53.24, 48.78, 55.47, 47.41, 52.86, 51.28,\n",
       "       54.17, 55.53, 53.85, 48.24, 46.58, 54.01, 59.36, 53.02, 56.31,\n",
       "       51.22, 56.33, 52.63, 51.48, 47.49, 47.65, 51.76, 51.7 , 49.1 ,\n",
       "       52.01, 46.61, 51.74, 55.81, 48.93, 59.92, 55.92, 53.49, 51.33,\n",
       "       50.36, 60.91, 55.31, 51.84, 53.95, 51.24, 53.63, 54.9 , 49.65,\n",
       "       54.71, 63.68, 49.96, 56.19, 58.72, 52.14, 58.29, 48.65, 50.83,\n",
       "       44.51, 57.5 , 46.49, 52.03, 48.27, 47.93, 48.31, 57.75, 56.16,\n",
       "       51.5 , 52.99, 55.62, 55.92, 46.41, 53.  , 52.  , 55.35, 55.46,\n",
       "       47.19, 58.07, 48.98, 50.59, 56.54, 53.27, 51.73, 54.47, 51.71,\n",
       "       55.77, 51.27, 54.46, 55.8 , 54.16, 46.7 , 51.42, 48.91, 50.  ,\n",
       "       53.59, 50.48, 49.89, 49.09, 49.88, 58.88, 48.54, 51.37, 57.75,\n",
       "       55.22, 56.5 , 50.68, 54.39, 54.18, 56.  , 54.26, 52.91, 53.88,\n",
       "       56.23, 54.89, 54.33, 44.82, 50.89, 48.51, 49.96, 55.99, 49.12,\n",
       "       54.31, 58.73, 54.07, 53.  , 55.28, 51.  , 54.75, 49.63, 53.51,\n",
       "       59.49, 55.33, 46.06, 55.11, 54.11, 57.41, 57.35, 52.06, 60.74,\n",
       "       60.06, 55.84, 50.84, 50.37, 47.42, 58.18, 51.48, 57.47, 47.39,\n",
       "       49.06, 54.68, 56.66, 48.77, 54.73, 55.3 , 52.22, 56.99, 50.51,\n",
       "       45.32, 52.74, 48.84, 64.2 , 52.12, 56.04, 50.61, 60.01, 56.02,\n",
       "       58.86, 59.01, 46.67, 46.72, 50.53, 56.18, 58.14, 52.09, 57.43,\n",
       "       48.99, 52.13, 56.86, 56.29, 52.28, 53.07, 47.08, 50.9 , 54.04,\n",
       "       60.01, 57.45, 53.45, 58.33, 58.67, 59.25, 56.23, 49.36, 55.66,\n",
       "       53.98, 55.75, 51.09, 52.82, 52.06, 50.96, 57.57, 53.68, 53.25,\n",
       "       55.41, 49.33, 57.68, 54.34, 62.32, 62.05, 50.12, 55.78, 53.25,\n",
       "       47.99, 48.93, 55.28, 48.66, 56.37, 53.  , 52.69, 52.63, 51.28,\n",
       "       56.55, 52.64, 49.78, 52.77, 54.59, 58.84, 53.16, 56.62, 55.75,\n",
       "       54.95, 57.75, 59.21, 53.16, 55.64, 54.55, 58.96, 59.57, 58.72,\n",
       "       55.81, 56.13, 50.32, 54.7 , 56.91, 57.71, 53.23, 54.1 , 57.24,\n",
       "       50.34, 55.43, 54.87, 54.69, 48.58, 55.55, 59.53, 52.73, 53.05,\n",
       "       55.65, 62.31, 58.09, 48.71, 60.94, 49.1 , 55.42, 60.55, 53.36,\n",
       "       50.17, 60.48, 51.08, 57.13, 47.62, 54.21, 54.19, 53.94, 55.27,\n",
       "       57.94, 53.3 , 50.  , 51.29, 51.39, 53.24, 52.72, 55.72, 47.42,\n",
       "       55.97, 58.14, 55.89, 50.04, 51.38, 54.84, 50.29, 51.54, 53.3 ,\n",
       "       50.86, 55.51, 52.11, 54.39, 48.74, 51.48, 58.61, 54.73, 51.87,\n",
       "       54.91, 59.1 , 50.47, 49.39, 59.2 , 60.54, 54.26, 49.98, 49.91,\n",
       "       53.96, 52.46, 50.66, 54.21, 47.97, 53.59, 56.55, 58.55, 55.46,\n",
       "       57.05, 46.59, 47.23, 54.92, 45.79, 53.36, 46.53, 63.91, 50.95,\n",
       "       49.99, 52.47, 52.01, 55.44, 54.51, 49.37, 61.18, 57.36, 60.71,\n",
       "       51.77, 54.54, 57.64, 48.51, 55.12, 54.76, 47.81, 55.99, 52.02,\n",
       "       48.87, 52.21, 50.63, 58.39, 57.14, 50.57, 58.76, 51.75, 48.44,\n",
       "       58.48, 57.29, 53.45, 51.9 , 54.76, 56.51, 59.8 , 57.19, 57.64,\n",
       "       54.54, 54.52, 57.4 , 54.13, 51.87, 49.45, 57.88, 50.5 , 52.61,\n",
       "       48.39, 52.21, 53.68, 57.66, 53.01, 52.43, 56.94, 59.08, 48.58,\n",
       "       55.72, 45.76, 54.03, 54.23, 57.64, 58.32, 55.64, 53.7 , 54.04,\n",
       "       56.66, 49.69, 59.24, 52.27, 49.3 , 48.05, 59.84, 45.36, 54.99,\n",
       "       48.74, 60.6 , 52.22, 49.07, 46.38, 55.66, 57.61, 56.03, 54.49,\n",
       "       53.13, 54.22, 50.95, 55.17, 57.24, 53.76, 56.7 , 53.6 , 61.19,\n",
       "       47.04, 53.59, 49.5 , 51.56, 56.97, 56.85, 58.58, 55.2 , 56.56,\n",
       "       59.72, 50.2 , 51.96, 56.9 , 47.06, 57.91, 49.06, 57.82, 57.24,\n",
       "       50.84, 51.88, 57.04, 58.4 , 49.11, 53.84, 59.05, 59.55, 48.11,\n",
       "       58.97, 56.08, 54.67, 57.47, 46.77, 57.11, 52.8 , 48.23, 48.88,\n",
       "       57.02, 52.49, 59.26, 50.46, 60.85, 54.82, 49.31, 50.65, 58.88,\n",
       "       55.3 , 50.52, 56.59, 59.49, 49.22, 48.62, 45.53, 48.33, 54.5 ,\n",
       "       54.51, 60.2 , 52.75, 50.2 , 56.17, 49.74, 62.74, 51.71, 53.12,\n",
       "       59.13, 54.54, 51.78, 55.34, 56.76, 55.47, 51.11, 44.93, 59.42,\n",
       "       49.26, 57.09, 54.81, 55.91, 53.32, 49.98, 60.28, 54.75, 54.78,\n",
       "       51.8 , 52.34, 53.81, 58.76, 60.43, 50.19, 53.85, 53.51, 52.38,\n",
       "       54.94, 49.24, 51.61, 59.12, 52.93, 53.06, 54.26, 51.68, 63.05,\n",
       "       48.29, 52.67, 58.  , 58.39, 48.75, 50.92, 48.55, 46.99, 49.87,\n",
       "       57.61, 48.61, 52.94, 48.71, 50.3 , 53.28, 49.24, 56.81, 53.64,\n",
       "       54.32, 55.48, 45.73, 43.78, 54.17, 50.31, 56.68, 53.41, 52.  ,\n",
       "       46.53, 56.22, 54.53, 52.78, 47.26, 46.4 , 58.54, 53.66, 54.22,\n",
       "       50.9 , 55.98, 61.64, 50.36, 46.56, 55.74, 51.29, 49.91, 48.59,\n",
       "       58.33, 62.33, 57.78, 47.16, 51.97, 54.29, 60.58, 47.3 , 46.01,\n",
       "       46.51, 49.08, 53.48, 54.84, 56.45, 56.75, 58.37, 62.26, 51.35,\n",
       "       50.63, 49.18, 57.34, 58.45, 53.62, 51.02, 52.25, 54.47, 50.24,\n",
       "       42.71, 50.81, 58.12, 48.88, 55.74, 45.91, 53.91, 53.38, 55.1 ,\n",
       "       49.93, 53.48, 55.34, 51.04, 49.2 , 53.94, 46.31, 51.61, 53.41,\n",
       "       51.66, 51.35, 50.11, 46.28, 55.25, 56.92, 64.46, 49.49, 50.53,\n",
       "       50.25, 52.23, 53.47, 45.3 , 56.97, 45.21, 53.19, 57.44, 54.81,\n",
       "       48.92, 49.76, 49.8 , 54.45, 56.55, 49.49, 56.79, 52.71, 50.42,\n",
       "       54.56, 52.54, 54.96, 51.57, 57.98, 54.07, 46.49, 47.9 , 55.57,\n",
       "       57.52, 56.91, 50.69, 55.58, 55.82, 57.34, 49.87, 55.08, 55.47,\n",
       "       54.03, 47.34, 56.82, 50.77, 55.65, 49.85, 59.39, 52.06, 59.98,\n",
       "       55.63, 56.18, 49.79, 57.33, 46.82, 50.13, 48.11, 47.05, 47.6 ,\n",
       "       55.2 , 55.75, 52.  , 55.3 , 50.83, 53.66, 49.25, 49.42, 57.01,\n",
       "       61.01, 49.92, 54.13, 59.82, 53.83, 52.49, 54.59, 48.61, 56.03,\n",
       "       56.2 , 55.1 , 47.72, 54.41, 57.12, 53.2 , 54.85, 53.34, 51.28,\n",
       "       50.99, 48.71, 50.52, 52.9 , 53.69, 51.32, 51.23, 49.21, 48.26,\n",
       "       47.96, 47.81, 55.22, 54.17, 62.24, 53.28, 53.14, 52.62, 56.98,\n",
       "       57.62, 49.11, 50.9 , 51.69, 56.58, 54.68, 61.69, 47.97, 46.93,\n",
       "       56.21, 48.78, 58.62, 48.81, 60.64, 51.69, 52.27, 55.36, 49.93,\n",
       "       51.81, 45.47])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.fit(X_transformed, y_train)\n",
    "base_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(base_model.predict(X_test))\n",
    "df.to_csv('pred_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 9, 'epsilon': 0.01}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "parameters = {'C':np.arange(5,10,1), 'epsilon':np.arange(0.01,0.1,0.02)}\n",
    "clf = GridSearchCV(SVR(), parameters, scoring='neg_mean_squared_error')\n",
    "clf.fit(X_transformed, y_train)\n",
    "clf.cv_results_['params'][np.argmax(clf.cv_results_['mean_test_score'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-160.55727928161784"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "clf = SVR(C= 9, epsilon = 0.01)\n",
    "scores = cross_validate(clf, X_transformed, y_train, cv=5, scoring=['neg_mean_squared_error'])['test_neg_mean_squared_error']\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Lewis/Brosnted  acid Sites'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, DotProduct, RBF\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seeds\n",
    "np.random.seed(seed=0)  # Set seed for NumPy\n",
    "random_state = 0\n",
    "# Instantiate a Gaussian Process model\n",
    "kernel = C(1.0, (1e-3, 1e3)) * RBF(10, (1e-2, 1e2))\n",
    "\n",
    "gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9, alpha= 0.000005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New random forest with only the two most important variables\n",
    "model = gpr \n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "scores = cross_validate(model, X_train, y_train, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "np.mean(scores.get('test_score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# # Labels are the values we want to predict\n",
    "# labels = np.array(labels)\n",
    "# # Remove the labels from the features\n",
    "# # Saving feature names for later use\n",
    "# feature_list = list(features.columns)\n",
    "# # Convert to numpy array\n",
    "# features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Random forest\n",
    "# # Using Skicit-learn to split data into training and testing sets\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# # Split the data into training and testing sets\n",
    "# train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "import sklearn\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 450.895 (329.351)\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Lasso(alpha=1.0)\n",
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, features, labels, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "# force scores to be positive\n",
    "scores = absolute(scores)\n",
    "print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (772, 52935)\n",
      "Training Labels Shape: (772,)\n",
      "Testing Features Shape: (193, 52935)\n",
      "Testing Labels Shape: (193,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average baseline error:  164.46\n"
     ]
    }
   ],
   "source": [
    "# The baseline predictions are the historical averages\n",
    "baseline_preds = np.mean(labels)\n",
    "# Baseline errors, and display average baseline error\n",
    "baseline_errors = (baseline_preds - test_labels)**2\n",
    "print('Average baseline error: ', round(np.mean(baseline_errors), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (3.8.1)",
   "language": "python",
   "name": "python3-3.8.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
